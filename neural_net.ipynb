{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20000 entries, 0 to 19999\n",
      "Data columns (total 15 columns):\n",
      "favourites_count                20000 non-null int64\n",
      "profile_use_background_image    20000 non-null object\n",
      "lang                            20000 non-null object\n",
      "followers_count                 20000 non-null int64\n",
      "protected                       20000 non-null object\n",
      "geo_enabled                     20000 non-null object\n",
      "verified                        20000 non-null object\n",
      "statuses_count                  20000 non-null int64\n",
      "friends_count                   20000 non-null int64\n",
      "numberoftweets                  19592 non-null float64\n",
      "percentoftweetsinwork           17235 non-null float64\n",
      "percentoftweetsinweekend        17235 non-null float64\n",
      "percentoftweetsinday            17235 non-null float64\n",
      "percentoftweetsinnight          17235 non-null float64\n",
      "identified_as_person            20000 non-null object\n",
      "dtypes: float64(5), int64(4), object(6)\n",
      "memory usage: 2.3+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "columns = ['favourites_count', 'profile_use_background_image', 'lang', 'followers_count',\n",
    "          'protected', 'geo_enabled', 'verified', 'statuses_count', 'friends_count', 'numberoftweets',\n",
    "          'percentoftweetsinwork', 'percentoftweetsinweekend', 'percentoftweetsinday', 'percentoftweetsinnight',\n",
    "          'identified_as_person']\n",
    "raw_data = pd.read_csv('users.csv', nrows=20000,  usecols=columns)\n",
    "\n",
    "print(raw_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['es' 'en' 'uk' 'pl' 'tr' 'ar' 'de' 'ko' 'cs' 'ca' 'ru' 'zh' 'pt' 'fr' 'no'\n",
      " 'id' 'ro' 'ja' 'sv' 'it' 'da' 'fi' 'nl' 'hu' 'th' 'sk' 'fil' 'bg' 'vi'\n",
      " 'el' 'bn' 'he' 'hr' 'sr' 'nb' 'hi' 'fa' 'lv' 'ta' 'sl']\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 17235 entries, 0 to 19985\n",
      "Data columns (total 15 columns):\n",
      "favourites_count                17235 non-null int64\n",
      "profile_use_background_image    17235 non-null bool\n",
      "lang                            17235 non-null object\n",
      "followers_count                 17235 non-null int64\n",
      "protected                       17235 non-null bool\n",
      "geo_enabled                     17235 non-null bool\n",
      "verified                        17235 non-null bool\n",
      "statuses_count                  17235 non-null int64\n",
      "friends_count                   17235 non-null int64\n",
      "numberoftweets                  17235 non-null float64\n",
      "percentoftweetsinwork           17235 non-null float64\n",
      "percentoftweetsinweekend        17235 non-null float64\n",
      "percentoftweetsinday            17235 non-null float64\n",
      "percentoftweetsinnight          17235 non-null float64\n",
      "identified_as_person            17235 non-null bool\n",
      "dtypes: bool(5), float64(5), int64(4), object(1)\n",
      "memory usage: 1.5+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Replace locale\n",
    "raw_data['lang'] = raw_data['lang'].str.replace(r'zh.*', 'zh')\n",
    "raw_data['lang'] = raw_data['lang'].str.replace(r'en.*', 'en')\n",
    "raw_data['lang'] = raw_data['lang'].str.replace(r'es.*', 'es')\n",
    "print(raw_data['lang'].unique())\n",
    "\n",
    "m = {'t': True, 'f': False}\n",
    "raw_data['profile_use_background_image'] = raw_data['profile_use_background_image'].map(m)\n",
    "raw_data['protected'] = raw_data['protected'].map(m)\n",
    "raw_data['geo_enabled'] = raw_data['geo_enabled'].map(m)\n",
    "raw_data['verified'] = raw_data['verified'].map(m)\n",
    "raw_data['identified_as_person'] = raw_data['identified_as_person'].map(m)\n",
    "\n",
    "for f in ['favourites_count', 'followers_count', 'friends_count', 'numberoftweets',\n",
    "          'percentoftweetsinwork', 'percentoftweetsinweekend', 'percentoftweetsinday',\n",
    "          'percentoftweetsinnight']:\n",
    "    raw_data = raw_data[np.isfinite(raw_data[f])]\n",
    "# print(raw_data.numberoftweets[raw_data.numberoftweets.isnull()])\n",
    "\n",
    "print(raw_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tahion/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "quant = 0.95\n",
    "fields = ['favourites_count', 'followers_count', 'statuses_count', 'friends_count', 'numberoftweets']\n",
    "\n",
    "# Remove top 5% of samples from following columns\n",
    "for field in fields:\n",
    "    q = raw_data[field].quantile(quant)\n",
    "    raw_data = raw_data[(raw_data[field] < q)] \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13334, 53)\n",
      "Person/Not person ratio in training samples: 0.7020903143449817\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding\n",
    "ml_data = pd.get_dummies(raw_data, columns=['lang']).values.astype(float)\n",
    "# 14 col is label\n",
    "\n",
    "train_set, test_set = train_test_split(ml_data, train_size = 0.8)\n",
    "print(ml_data.shape)\n",
    "idx = [i for i in range(np.shape(ml_data)[1]) if i not in [13]]\n",
    "train_x = train_set[:, idx]   # all but 13th column\n",
    "train_y = train_set[:, 13]\n",
    "\n",
    "test_x = test_set[:, idx]\n",
    "test_y = test_set[:, 13]\n",
    "\n",
    "\n",
    "train_x = scale(train_x)\n",
    "test_x = scale(test_x)\n",
    "\n",
    "train_y = np.ravel(train_y)\n",
    "test_y = np.ravel(test_y)\n",
    "\n",
    "print(\"Person/Not person ratio in training samples: %s\" % (len(train_y[train_y==1])/len(train_y[train_y==0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/tahion/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "np.random.seed(1337)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "10667/10667 [==============================] - 1s 129us/step - loss: 0.6370 - acc: 0.6458\n",
      "Epoch 2/15\n",
      "10667/10667 [==============================] - 1s 48us/step - loss: 0.6174 - acc: 0.6720\n",
      "Epoch 3/15\n",
      "10667/10667 [==============================] - 1s 51us/step - loss: 0.6136 - acc: 0.6724\n",
      "Epoch 4/15\n",
      "10667/10667 [==============================] - 1s 48us/step - loss: 0.6120 - acc: 0.6726\n",
      "Epoch 5/15\n",
      "10667/10667 [==============================] - 1s 48us/step - loss: 0.6112 - acc: 0.6736\n",
      "Epoch 6/15\n",
      "10667/10667 [==============================] - 1s 47us/step - loss: 0.6085 - acc: 0.6736\n",
      "Epoch 7/15\n",
      "10667/10667 [==============================] - 1s 49us/step - loss: 0.6067 - acc: 0.6741\n",
      "Epoch 8/15\n",
      "10667/10667 [==============================] - 1s 49us/step - loss: 0.6058 - acc: 0.6750\n",
      "Epoch 9/15\n",
      "10667/10667 [==============================] - 1s 48us/step - loss: 0.6033 - acc: 0.6739\n",
      "Epoch 10/15\n",
      "10667/10667 [==============================] - 1s 50us/step - loss: 0.6021 - acc: 0.6767\n",
      "Epoch 11/15\n",
      "10667/10667 [==============================] - 1s 50us/step - loss: 0.6033 - acc: 0.6733\n",
      "Epoch 12/15\n",
      "10667/10667 [==============================] - 1s 48us/step - loss: 0.5981 - acc: 0.6779\n",
      "Epoch 13/15\n",
      "10667/10667 [==============================] - 1s 47us/step - loss: 0.5970 - acc: 0.6784\n",
      "Epoch 14/15\n",
      "10667/10667 [==============================] - 1s 50us/step - loss: 0.5956 - acc: 0.6791\n",
      "Epoch 15/15\n",
      "10667/10667 [==============================] - 1s 48us/step - loss: 0.5921 - acc: 0.6782\n",
      "2667/2667 [==============================] - 0s 61us/step\n",
      "\n",
      "acc: 65.09%\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=train_x.shape[1], activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, epochs=15, batch_size=100)\n",
    "\n",
    "scores = model.evaluate(test_x, test_y)\n",
    "print(\"\\n%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
